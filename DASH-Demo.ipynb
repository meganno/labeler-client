{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d52f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labeler_ui import Authentication, Dashboard\n",
    "from labeler_client import Service\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401399a",
   "metadata": {},
   "source": [
    "# Connecting to the service\n",
    "We provide a shared project to simuliate the real-world collaboration among data science practitioners. This project is pre-loaded with a small set of [tweets about US airlines](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment). Required labeling schema and meta-data are also pre-loaded (shown as screen shots in later cells). Please do not change these setups.\n",
    "\n",
    "To start, connect to our service using one of our demo users's token. Note token sharing is for the demostration purposes only, and might cause potential overwrite of other's annotation. In real projects, each user own their unique token.\n",
    "\n",
    "**Run the cells below to connect to the demo project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9924b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting demo token.\n",
    "demo_user_id=5 # choose between 1-5\n",
    "tokens = pd.read_csv('tokens.csv',index_col='id')\n",
    "demo_token = tokens.loc[demo_user_id,'token'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to service\n",
    "demo = Service(project='development',token=demo_token,\n",
    "               host='http://labeler-demo-service-alb-1400746965.us-west-1.elb.amazonaws.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cb2bd",
   "metadata": {},
   "source": [
    "# View label schema\n",
    "Here the schema is pre-set to collect one label named *sentiment* which corresponds to a classification task and a label named *sp* which correponds to an extraction task (selecting spans out of a document).\n",
    "\n",
    "**Run the cell below to check the schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61163579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the pre-set demo schema\n",
    "demo.get_schemas().value(active=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ce9e3",
   "metadata": {},
   "source": [
    "# Try annotating\n",
    "\n",
    "Here we show the basic annoation widget.\n",
    "\n",
    "**Run the cell below to bring up the widget to annotate the first 10 examples**\n",
    "You can switch between the *single* and *table* view on the top-right corner. Switch back to the table view, check the top checkbox on the second column and click **submit** button on the top-left corner to send your annotations to the backend. \n",
    "\n",
    "You can also click the *Annotating* button with a dropdown on the top-right corner to switch between annotation and reconciling mode. In the reconciling mode, you could look over distributions of existing annotations from all annotators and resolve conflicts.\n",
    "\n",
    "(Note some data might already have annotations if someone else sharing the same token already annotated the data point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search results => subset s1\n",
    "s1 = demo.search(keyword='', limit=10, start=0)\n",
    "# bring up a widget \n",
    "s1.show({'view':'table'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4539b",
   "metadata": {},
   "source": [
    "# Show contexual data\n",
    "There are cases when contextual information could help or speed up the annotatin process. Here we demonstrate with a pre-loaded \"hashtag\" metadata, which was generated using the code shown in this screenshot:\n",
    "![generating the hashtag meta-data](Figures/hashtag.png)\n",
    "\n",
    "In real projects, the metadata could be generated using user-defined functions, like in the screenshot.\n",
    "\n",
    "**Run the cell below to see how hashtags are shown as auxiliary information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2= demo.search(keyword='delay',\n",
    "                  limit=50,\n",
    "                  start=0, \n",
    "                  meta_names=['hashtag'])\n",
    "s2.show()\n",
    "#hover over in the table view to see the hashtage for each data ponint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54382730",
   "metadata": {},
   "source": [
    "# Exploratory annotation: heuristic-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c75f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3= demo.search(keyword='fail',\n",
    "                  limit=50,\n",
    "                  start=0)\n",
    "s3.show({'view':'table'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8304ff7",
   "metadata": {},
   "source": [
    "# Exploratory annotation: similarity-based suggestions \n",
    "In addition to relying on user's heuristic, meganno also provide automated suggestions, based on all kinds of metadata. Here we give an example using sentence bert embeddings. The embeddings have been generated ahead of time using the script shown in the screenshot below:\n",
    "\n",
    "![generating bert embedding](./Figures/bert.png)\n",
    "Based on the embedding, suggest the most similar datapoints from the database.\n",
    "\n",
    "In real projects, users can bring\n",
    "*Try Below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32006fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = demo.search(keyword='delay', limit=3, start=0)\n",
    "# try replacing the keyword here to test the similarity search \n",
    "s5 = s4.suggest_similar('bert-embedding', limit=4)# needs to provide a valid meta_name\n",
    "s5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a81124",
   "metadata": {},
   "source": [
    "# Analysis Dashboard to track project progress.\n",
    "At any stage of the project, you can run the cell below to track the progress of all annnotators, look at class distibutions, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746dc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis\n",
    "from labeler_ui import Dashboard\n",
    "dash_wg = Dashboard(demo)\n",
    "dash_wg.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting all annotations to csv if need to bring data out.\n",
    "demo.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea9124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}